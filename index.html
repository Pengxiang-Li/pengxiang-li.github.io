<!DOCTYPE HTML>
<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Pengxiang Li</title>

  <!-- <meta name="author" content="Puhao Li">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="msvalidate.01" content="1D6EAEB9C6558C0BB977413398D67E91" /> -->

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" href="images/icon.svg">
</head>

<body>
  <table
    style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr style="padding:0px">
                <td style="padding:2.5%;width:63%;vertical-align:middle">
                  <p style="text-align:center">
                    <name>Pengxiang Li</name>
                  </p>
                  <p style="text-align: justify">
                    I am a second-year PhD student in Beijing Institute of Technology(BIT), advised by <a
                      href="https://wu-yuwei-bit.github.io/" target="_blank">Dr. Yuwei Wu</a> and <a
                      href="https://scholar.google.com/citations?user=Sl6TV7gAAAAJ&hl=en/" target="_blank">Dr. Yunde
                      Jia</a>.
                    I am also a member of the joint PhD program ('TONG Program') with Beijing Institute for General
                    Artificial Intelligence(BIGAI), and I am grateful to be advised by <a href="https://liqing.io/"
                      target="_blank">Dr. Qing Li</a> and <a href="https://zhigao2017.github.io/" target="_blank">Dr.
                      Zhi Gao</a>.
                    Previously, I got my Bachelor's degree in Computer Science and Technology from BIT in 2021.
                    <br><br>
                    My research interests lie in Vision and Language, non-Euclidean representation learning, and 3D
                    vision.
                    Specifically, I am interested in building the feedback refining systems for multi-modal models.
                  </p>
                  <p style="text-align:center">
                    <a href="mailto:pengxiangli1999@gmail.com">Email</a> &nbsp/&nbsp
                    <a href="https://github.com/Pengxiang-Li/" target="_blank">Github</a>
                  </p>
                </td>
                <td style="padding:2.5%;width:35%;max-width:35%">
                  <a href="images/Personal/Pengxiang.jpg"><img style="width:100%;max-width:100%" alt="profile photo"
                      src="images/Personal/Pengxiang.jpg" class="hoverZoomLink"></a>
                </td>
              </tr>
            </tbody>
          </table>


          <table
          style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>
            <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <heading>News</heading>
              </td>
            </tr>

          </tbody>
        </table>

        <table
        style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
        <tbody>
          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <p style="text-align: left">
             [2024.10] ðŸŒŸ One paper on Feedback learning in VLM is accepted by Neurips 2024.
             <br>
             [2024.09] ðŸŒŸ One journal paper on Stereo Matching is accepted by T-CSVT. </p>
               
            </td>
          </tr>

        </tbody>
      </table>



          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <heading>Research</heading>
                </td>
              </tr>
            </tbody>
          </table>
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <img src='images/Research/sg3d.jpg' width="195">
                  </div>
                  </div>
                </td>
                <td style="padding:20px;width:75%;vertical-align:top">
                  <papertitle>Task-oriented Sequential Grounding in 3D Scenes
                  </papertitle>
                  <br>
                  Zhuofan Zhang, Ziyu Zhu, <strong>Pengxiang Li</strong>, Tengyu Liu, Xiaojian Ma, Yixin Chen, Baoxiong Jia, Siyuan Huang, Qing Li
                  
                  <br>
                  <br>
                  Preprint, 2024
                  <br>
                  <a href="https://arxiv.org/abs/2408.04034"> [Arxiv] </a>
                  <a href="https://sg-3d.github.io"> [Website] </a> 
                  <a href="https://github.com/sg-3d/sg3d"> [Code] </a> 
                  <a href="https://huggingface.co/datasets/ZhuofanZhang/SG3D"> [Dataset] </a> 
                  <a href="https://huggingface.co/spaces/li-qing/SG3D-Demo"> [Demo] </a>
                  <a href="https://youtu.be/oo72uZRh8DY"> [YouTube] </a>
                  &nbsp
                  <br>

                  <br>
                  <em style="color: darkred;"> We proposed a new task, Task-oriented Sequential Grounding in 3D scenes, and introduced SG3D, a large-scale dataset with 22,346 tasks and 112,236 steps in 4,895 real-world 3D scenes. 
                    </em>
                </td>

                
              </tr>  

              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <img src='images/Research/fire.jpg' width="195">
                  </div>
                  </div>
                </td>
                <td style="padding:20px;width:75%;vertical-align:top">
                  <papertitle>FIRE: A Dataset for Feedback Integration and Refinement Evaluation of Multimodal Models
                  </papertitle>
                  <br>
                  <strong>Pengxiang Li*</strong>, Zhi Gao*,  Bofei Zhang*,  Tao Yuan, Yuwei Wu, Mehrtash Harandi, Yunde Jia, Song-Chun Zhu, Qing Li
                  
                  <br>
                  <br>
                  Neurips, 2024
                  <br>
                  <a href="https://arxiv.org/abs/2407.11522"> [Arxiv] </a> 
                  <a href="https://mm-fire.github.io/"> [Website] </a> 
                  <a href="https://github.com/MM-FIRE/FIRE"> [Code] </a> 
                  <a href="https://huggingface.co/datasets/PengxiangLi/FIRE"> [Dataset] </a> 
                  <a href="https://huggingface.co/li-qing/llava-next-llama3-8b-student-fire/tree/main"> [Model] </a> 
                  <a href="https://youtu.be/PYPuZn8RjCE?si=WZtgTsos4Wy97G9F"> [YouTube] </a>
                  &nbsp
                  <br>

                  <br>
                  <em style="color: darkred;"> A feedback-refinement dataset with 1.1M multi-turn conversations, which empowers VLMs to refine their responses based on given feedback. 
                    </em>
                </td>

                
              </tr>  
              <!-- Inter-Scale Similarity Guided Cost Aggregation for Stereo Matching -->

              <tr>

                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <img src='images/Research/issga.jpg' width="195">
                  </div>
                  </div>
                </td>
                <td style="padding:20px;width:75%;vertical-align:top">
                  <papertitle>Inter-Scale Similarity Guided Cost Aggregation for Stereo Matching
                  </papertitle>
                  <br>
                  <strong>Pengxiang Li</strong>, Chengtang Yao, Yunde Jia, Yuwei Wu
                  
                  <br>
                  <br>
                  Early Accepted by T-CSVT, 2024
                  <br>
                  <a href="https://ieeexplore.ieee.org/document/10663688"> [Paper] </a> 
                  &nbsp
                  <br>

                  <br>
                  <em style="color: darkred;">A plug-and-play module of inter-scale similarity guided cost
                    aggregation to adaptively recover details in fine-grained areas for stereo matching.
                    </em>
                </td>

                
              </tr>  

              <tr>

                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <img src='images/Research/tutorial.jpg' width="195">
                  </div>
                  </div>
                </td>
                <td style="padding:20px;width:75%;vertical-align:top">
                  <papertitle>Hyperbolic Learning: Theory and Applications
                  </papertitle>
                  <br>
                  <strong>Pengxiang Li</strong>, Peilin Yu, Yangkai Xue, Yuwei Wu , Zhi Gao
                  
                  <br>
                  <br>
                  Tutorial, 2023
                  <br>
                  <a href="https://github.com/Pengxiang-Li/HyperbolicTutorial/blob/main/Tutorial-2023-Hyperbolic-Learning-Theory-and-Applications.pdf"> [Slide] </a> 
                  &nbsp
                  <br>

                  <br>
                  <em style="color: darkred;">A tutorial explores hyperbolic learning's theoretical underpinnings and applications, highlighting its advantages in modeling hierarchical data in diverse downstream felds.
                    </em>
                </td>

                
              </tr>  
      
              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <img src='images/Research/Decnet.png' width="195">
                  </div>
                  </div>
                </td>
                <td style="padding:20px;width:75%;vertical-align:top">
                  <papertitle>A Decomposition Model for Stereo Matching
                  </papertitle>
                  <br>
                  Chengtang Yao, Yunde Jia, Huijun Di* , <strong>Pengxiang Li</strong>, Yuwei Wu
                  
                  <br>
                  <br>
                  CVPR, 2021
                  <br>
                  <a href="http://openaccess.thecvf.com/content/CVPR2021/papers/Yao_A_Decomposition_Model_for_Stereo_Matching_CVPR_2021_paper.pdf"
                    target="_blank">[Paper]</a>
                  <a href="https://github.com/YaoChengTang/DecNet" target="_blank">[Code]</a> 
                  <a href="https://openaccess.thecvf.com/content/CVPR2021/supplemental/Yao_A_Decomposition_Model_CVPR_2021_supplemental.pdf" target="_blank">[Supp]</a> 
                  &nbsp
                  <br>

                  <br>
                  <em style="color: darkred;">A a decomposition model for
                    stereo matching to solve the problem of excessive growth
                    in computational cost (time and memory cost) as the resolution increases.
                    </em>
                </td>
              </tr>

              
            </tbody>
          </table>

          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <heading>Experience</heading>
                </td>
              </tr>
            </tbody>
          </table>
          <table width="100%" align="center" border="0" cellpadding="20">
            <tbody>
              
              <tr>
                <td style="padding:10px;width:18px;vertical-align:middle"><img src="images/Institution/bigai.png" ,
                    width="100px"></td>
                <td width="90%" valign="center">
                  <b>Beijing Institute for General Artificial Intelligence(BIGAI)</b>, China
                  <br> 2024.02 - Now
                  <br>
                  <br> <b>Joint training PhD student</b>
                  <br> Advisor: <a href="https://liqing.io/"
                  target="_blank">Dr. Qing Li</a> and <a href="https://zhigao2017.github.io/" target="_blank">Dr.
                  Zhi Gao</a>.
                </td>
              </tr>
              <tr>
                <td style="padding:10px;width:18px;vertical-align:middle"><img src="images/Institution/bit-1.png" ,
                    width="100px"></td>
                <td width="90%" valign="center">
                  <b>Beijing Institute of Technology</b>, China
                  <br>
                  <br> <b>Master student </b> 2021.09 - 2023.07
                  <br> <b>PhD student </b> 2023.9 - Now
                  <br> Advisor: 
                  <a href="https://wu-yuwei-bit.github.io/" target="_blank">Dr. Yuwei Wu</a> and <a
                  href="https://scholar.google.com/citations?user=Sl6TV7gAAAAJ&hl=en/" target="_blank">Dr. Yunde
                  Jia</a>
                </td>
              </tr>
              
              <!-- <tr>
                <td style="padding:10px;width:18px;vertical-align:middle"><img src="images/Institution/bit-1.png" ,
                    width="100px"></td>
                <td width="90%" valign="center">
                  <b>Beijing Institute of Technology</b>, China
                  <br> 2021.09 - 2023.09
                  <br>
                  <br> <b>Master student</b>
                  <br> Advisor: 
                  <a href="https://wu-yuwei-bit.github.io/" target="_blank">Dr. Yuwei Wu</a> and <a
                  href="https://scholar.google.com/citations?user=Sl6TV7gAAAAJ&hl=en/" target="_blank">Dr. Yunde
                  Jia</a>
                </td>
              </tr> -->
              <tr>
                <td style="padding:10px;width:18px;vertical-align:middle"><img src="images/Institution/bit-1.png" ,
                    width="100px"></td>
                <td width="90%" valign="center">
                  <b>Beijing Institute of Technology</b>, China
                  <br> 2017.08 - 2021.06
                  <br>
                  <br> <b>Undergraduate Student</b>
                  <br> Advisor: 
                  <a href="https://scholar.google.com/citations?hl=en&user=b2DzFF8AAAAJ&view_op=list_works&sortby=pubdate" target="_blank">Dr. Xian-Ling Mao</a> 
                </td>
              </tr>
            </tbody>
          </table>


          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:0px">
                  <br>
                  <p style="text-align:right;font-size:small;">
                    Thanks for your visiting by &#128522.
                    <br>
                    Template stolen from <a href="https://jonbarron.info/" style="text-align:right;font-size:small;"
                      target="_blank">Jon Barron</a>.
                    Page icon made by <a href="https://www.flaticon.com/authors/freepik"
                      style="text-align:right;font-size:small;" target="_blank">Freepik</a>
                    from <a href="https://www.flaticon.com/" style="text-align:right;font-size:small;"
                      target="_blank">flaticon.com</a> .
                    <!-- <br>
          Last updated: Oct. 6, 2022 -->
                  </p>
                </td>
              </tr>
              
            </tbody>
          </table>
        </td>
      </tr>
  </table>
</body>

</html>
